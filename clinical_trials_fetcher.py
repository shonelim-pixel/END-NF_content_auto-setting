"""
============================================================
END NF ì½˜í…ì¸  ì‹œìŠ¤í…œ - ì„ìƒì‹œí—˜ ìˆ˜ì§‘ê¸°
============================================================
ClinicalTrials.gov API v2ë¥¼ ì‚¬ìš©í•˜ì—¬ NF ê´€ë ¨ ì„ìƒì‹œí—˜ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python clinical_trials_fetcher.py
    python clinical_trials_fetcher.py --status RECRUITING
    python clinical_trials_fetcher.py --query "selumetinib"
"""

import os
import json
from datetime import datetime
import argparse

try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    import urllib.request
    HAS_REQUESTS = False


def http_get(url: str, timeout: int = 30) -> str:
    if HAS_REQUESTS:
        resp = requests.get(url, timeout=timeout, headers={"User-Agent": "ENDNF-ContentBot/1.0"})
        resp.raise_for_status()
        return resp.text
    else:
        req = urllib.request.Request(url, headers={"User-Agent": "ENDNF-ContentBot/1.0"})
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            return resp.read().decode("utf-8")


BASE_URL = "https://clinicaltrials.gov/api/v2/studies"

DEFAULT_QUERIES = [
    "neurofibromatosis",
    "NF1 plexiform neurofibroma",
    "schwannomatosis",
    "neurofibromatosis type 2",
]


class ClinicalTrialsFetcher:
    """ClinicalTrials.gov API v2 ì„ìƒì‹œí—˜ ìˆ˜ì§‘ê¸°"""

    def search(
        self,
        query: str = "neurofibromatosis",
        status: list = None,
        max_results: int = 20,
        sort: str = "LastUpdatePostDate",
    ) -> list:
        """
        ì„ìƒì‹œí—˜ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ì–´
            status: ìƒíƒœ í•„í„° (RECRUITING, ACTIVE_NOT_RECRUITING ë“±)
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            sort: ì •ë ¬ ê¸°ì¤€

        Returns:
            ì„ìƒì‹œí—˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        if status is None:
            status = ["RECRUITING", "NOT_YET_RECRUITING", "ACTIVE_NOT_RECRUITING"]

        print(f"  ğŸ”¬ ì„ìƒì‹œí—˜ ê²€ìƒ‰: '{query}'")
        print(f"     ìƒíƒœ: {', '.join(status)}")

        # API v2 íŒŒë¼ë¯¸í„°
        params = [
            f"query.term={query}",
            f"pageSize={max_results}",
            f"sort={sort}",
        ]

        # ìƒíƒœ í•„í„°
        for s in status:
            params.append(f"filter.overallStatus={s}")

        # í•„ìš”í•œ í•„ë“œë§Œ ìš”ì²­
        fields = [
            "NCTId", "BriefTitle", "OfficialTitle",
            "OverallStatus", "StartDate", "CompletionDate",
            "BriefSummary", "Condition", "InterventionName",
            "LeadSponsorName", "Phase", "EnrollmentCount",
            "StudyType", "LocationCity", "LocationCountry",
            "LastUpdatePostDate",
        ]

        url = f"{BASE_URL}?{'&'.join(params)}"
        print(f"     URL: {url[:100]}...")

        try:
            data = json.loads(http_get(url))
            studies = data.get("studies", [])
            total = data.get("totalCount", 0)
            print(f"     â†’ ì´ {total}ê±´ ì¤‘ {len(studies)}ê±´ ìˆ˜ì§‘")
            return self._parse_studies(studies)
        except Exception as e:
            print(f"     âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _parse_studies(self, studies: list) -> list:
        """API ì‘ë‹µ íŒŒì‹±"""
        parsed = []
        for study in studies:
            try:
                protocol = study.get("protocolSection", {})
                ident = protocol.get("identificationModule", {})
                status_mod = protocol.get("statusModule", {})
                desc = protocol.get("descriptionModule", {})
                cond_mod = protocol.get("conditionsModule", {})
                interv_mod = protocol.get("armsInterventionsModule", {})
                sponsor_mod = protocol.get("sponsorCollaboratorsModule", {})
                design_mod = protocol.get("designModule", {})
                enroll_mod = design_mod.get("enrollmentInfo", {})
                contact_mod = protocol.get("contactsLocationsModule", {})

                # ì¹˜ë£Œ ë°©ë²•
                interventions = []
                if interv_mod:
                    for interv in interv_mod.get("interventions", []):
                        interventions.append({
                            "name": interv.get("name", ""),
                            "type": interv.get("type", ""),
                            "description": interv.get("description", "")[:200],
                        })

                # ì—°êµ¬ ì¥ì†Œ
                locations = []
                if contact_mod:
                    for loc in contact_mod.get("locations", [])[:5]:
                        locations.append({
                            "facility": loc.get("facility", ""),
                            "city": loc.get("city", ""),
                            "country": loc.get("country", ""),
                        })

                nct_id = ident.get("nctId", "")
                parsed.append({
                    "nct_id": nct_id,
                    "title": ident.get("briefTitle", ""),
                    "official_title": ident.get("officialTitle", ""),
                    "status": status_mod.get("overallStatus", ""),
                    "phase": design_mod.get("phases", []),
                    "study_type": design_mod.get("studyType", ""),
                    "start_date": status_mod.get("startDateStruct", {}).get("date", ""),
                    "completion_date": status_mod.get("completionDateStruct", {}).get("date", ""),
                    "last_update": status_mod.get("lastUpdatePostDateStruct", {}).get("date", ""),
                    "brief_summary": desc.get("briefSummary", "")[:500],
                    "conditions": cond_mod.get("conditions", []),
                    "interventions": interventions,
                    "sponsor": sponsor_mod.get("leadSponsor", {}).get("name", ""),
                    "enrollment": enroll_mod.get("count", 0),
                    "locations": locations,
                    "url": f"https://clinicaltrials.gov/study/{nct_id}",
                    "fetched_at": datetime.now().isoformat(),
                })
            except Exception as e:
                print(f"     âš ï¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
                continue

        return parsed

    def fetch_all_nf(self, max_per_query: int = 10) -> dict:
        """ëª¨ë“  NF ê´€ë ¨ ì¿¼ë¦¬ë¡œ ì„ìƒì‹œí—˜ ìˆ˜ì§‘"""
        print("=" * 60)
        print("ğŸ”¬ ClinicalTrials.gov NF ì„ìƒì‹œí—˜ ìˆ˜ì§‘")
        print("=" * 60)

        results = {}
        seen_ncts = set()

        for query in DEFAULT_QUERIES:
            trials = self.search(query, max_results=max_per_query)
            unique = []
            for trial in trials:
                if trial["nct_id"] not in seen_ncts:
                    seen_ncts.add(trial["nct_id"])
                    unique.append(trial)
            results[query] = unique
            print(f"     (ê³ ìœ : {len(unique)}ê±´)\n")

        total = sum(len(v) for v in results.values())
        print(f"âœ… ì´ {total}ê±´ì˜ ê³ ìœ  ì„ìƒì‹œí—˜ ìˆ˜ì§‘ ì™„ë£Œ")
        return results

    def fetch_recruiting_only(self, max_results: int = 20) -> list:
        """ëª¨ì§‘ ì¤‘ì¸ NF ì„ìƒì‹œí—˜ë§Œ ìˆ˜ì§‘"""
        return self.search(
            "neurofibromatosis",
            status=["RECRUITING"],
            max_results=max_results,
        )


def save_results(data, filename: str):
    output_dir = os.path.join(os.path.dirname(__file__), "data")
    os.makedirs(output_dir, exist_ok=True)
    filepath = os.path.join(output_dir, filename)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {filepath}")
    return filepath


def main():
    parser = argparse.ArgumentParser(description="END NF ì„ìƒì‹œí—˜ ìˆ˜ì§‘ê¸°")
    parser.add_argument("--query", type=str, default="", help="ê²€ìƒ‰ì–´")
    parser.add_argument("--status", type=str, default="RECRUITING",
                        help="ìƒíƒœ í•„í„° (RECRUITING, ACTIVE_NOT_RECRUITING ë“±)")
    parser.add_argument("--max", type=int, default=20, help="ìµœëŒ€ ê²°ê³¼ ìˆ˜")
    parser.add_argument("--output", type=str, default="", help="ì¶œë ¥ íŒŒì¼ëª…")
    args = parser.parse_args()

    fetcher = ClinicalTrialsFetcher()

    if args.query:
        results = fetcher.search(args.query, [args.status], args.max)
        filename = args.output or f"trials_custom_{datetime.now().strftime('%Y%m%d')}.json"
        save_results(results, filename)
    else:
        results = fetcher.fetch_all_nf(args.max)
        filename = args.output or f"trials_nf_{datetime.now().strftime('%Y%m%d')}.json"
        save_results(results, filename)


if __name__ == "__main__":
    main()
